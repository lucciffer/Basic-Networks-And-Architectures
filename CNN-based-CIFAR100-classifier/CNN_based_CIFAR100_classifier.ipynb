{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "CNN-based-CIFAR100-classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7vLHGJ9TdqG",
        "outputId": "81f33a9b-6d49-40a1-e197-156553c51581"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat May  8 06:29:59 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYS21CLQsJWe"
      },
      "source": [
        "# **Model Training** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTc3pbeaTIu8"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pickle\n",
        "import h5py\n",
        "#import pandas as pd\n",
        "\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import cifar100\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJ7c7QsnTIvV",
        "outputId": "54f9f181-d5de-4aac-defb-eaf62c386e88"
      },
      "source": [
        "classes = 100\n",
        "current_path = os.path.join(os.getcwd(), 'current_model')\n",
        "#print(current_path)\n",
        "#model_name = 'cifar100.h5'\n",
        "(x_train, y_train) , (x_test, y_test) = cifar100.load_data()\n",
        "print('x_train_dims : ' , x_train.shape)\n",
        "print('x_test_dims : ', x_test.shape)\n",
        "print('y_train_dims : ', y_train.shape)\n",
        "print('y_test_dims : ', y_test.shape)\n",
        "\n",
        "print( 'number of training examples available : ', x_train.shape[0])\n",
        "print('number of testing examples available : ', x_test.shape[0])\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, classes)\n",
        "y_test = keras.utils.to_categorical(y_test, classes)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "x_train /= 255.0\n",
        "x_test /= 255.0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 2s 0us/step\n",
            "x_train_dims :  (50000, 32, 32, 3)\n",
            "x_test_dims :  (10000, 32, 32, 3)\n",
            "y_train_dims :  (50000, 1)\n",
            "y_test_dims :  (10000, 1)\n",
            "number of training examples available :  50000\n",
            "number of testing examples available :  10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30YTKe8TTIvZ"
      },
      "source": [
        "model = Sequential()\n",
        "# layer one\n",
        "model.add(Conv2D(128,(3,3), padding = 'same', input_shape = x_train.shape[1:]))\n",
        "model.add(Activation('elu'))\n",
        "model.add(Conv2D(128, (3,3)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "#layer two\n",
        "model.add(Conv2D(256, (3, 3), padding='same'))\n",
        "model.add(Activation('elu'))\n",
        "model.add(Conv2D(256, (3, 3)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "#layer three\n",
        "model.add(Conv2D(512, (3, 3), padding='same'))\n",
        "model.add(Activation('elu'))\n",
        "model.add(Conv2D(512, (3, 3)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024))\n",
        "model.add(Activation('elu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(classes))\n",
        "model.add(Activation(\"softmax\"))\n",
        "\n",
        "\n",
        "opt = keras.optimizers.RMSprop(lr=0.0001, decay = 1e-6)\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer=opt, metrics = ['accuracy'])\n",
        "\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5-yejE4TIvc",
        "outputId": "35cf7b57-5031-47a1-9b14-c20d1af2eef3"
      },
      "source": [
        "epochs = 200\n",
        "data_augmentation = False\n",
        "predictions = 20\n",
        "batch_size = 64\n",
        "validation = []\n",
        "\n",
        "model.fit(x_train, y_train, batch_size= batch_size, epochs = epochs, validation_data = (x_test, y_test), shuffle = True)\n",
        "model.save(\"final_model.h5\")\n",
        "    \n",
        "        \n",
        "pickle.dump(validation, open(\"loss_validation.p\",'wb'))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "782/782 [==============================] - 63s 38ms/step - loss: 4.2053 - accuracy: 0.0665 - val_loss: 3.6213 - val_accuracy: 0.1556\n",
            "Epoch 2/200\n",
            "782/782 [==============================] - 29s 38ms/step - loss: 3.4407 - accuracy: 0.1906 - val_loss: 2.9697 - val_accuracy: 0.2822\n",
            "Epoch 3/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 3.0224 - accuracy: 0.2650 - val_loss: 2.7236 - val_accuracy: 0.3317\n",
            "Epoch 4/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 2.7728 - accuracy: 0.3134 - val_loss: 2.5402 - val_accuracy: 0.3625\n",
            "Epoch 5/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 2.5547 - accuracy: 0.3576 - val_loss: 2.3512 - val_accuracy: 0.4067\n",
            "Epoch 6/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 2.3952 - accuracy: 0.3932 - val_loss: 2.2216 - val_accuracy: 0.4344\n",
            "Epoch 7/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 2.2385 - accuracy: 0.4302 - val_loss: 2.1692 - val_accuracy: 0.4464\n",
            "Epoch 8/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 2.0961 - accuracy: 0.4606 - val_loss: 2.1516 - val_accuracy: 0.4559\n",
            "Epoch 9/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 1.9842 - accuracy: 0.4828 - val_loss: 2.0425 - val_accuracy: 0.4779\n",
            "Epoch 10/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 1.8745 - accuracy: 0.5062 - val_loss: 1.9858 - val_accuracy: 0.4881\n",
            "Epoch 11/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 1.7631 - accuracy: 0.5325 - val_loss: 1.9503 - val_accuracy: 0.5018\n",
            "Epoch 12/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 1.6643 - accuracy: 0.5539 - val_loss: 1.9132 - val_accuracy: 0.5141\n",
            "Epoch 13/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 1.5492 - accuracy: 0.5800 - val_loss: 1.9206 - val_accuracy: 0.5161\n",
            "Epoch 14/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 1.4277 - accuracy: 0.6070 - val_loss: 1.8413 - val_accuracy: 0.5303\n",
            "Epoch 15/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 1.3640 - accuracy: 0.6238 - val_loss: 1.8745 - val_accuracy: 0.5307\n",
            "Epoch 16/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 1.2348 - accuracy: 0.6542 - val_loss: 1.8592 - val_accuracy: 0.5347\n",
            "Epoch 17/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 1.1737 - accuracy: 0.6682 - val_loss: 1.8938 - val_accuracy: 0.5363\n",
            "Epoch 18/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 1.0783 - accuracy: 0.6937 - val_loss: 1.8853 - val_accuracy: 0.5347\n",
            "Epoch 19/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.9969 - accuracy: 0.7141 - val_loss: 1.8771 - val_accuracy: 0.5384\n",
            "Epoch 20/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.9237 - accuracy: 0.7323 - val_loss: 1.8934 - val_accuracy: 0.5410\n",
            "Epoch 21/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.8505 - accuracy: 0.7518 - val_loss: 1.9433 - val_accuracy: 0.5470\n",
            "Epoch 22/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.7871 - accuracy: 0.7671 - val_loss: 1.9713 - val_accuracy: 0.5438\n",
            "Epoch 23/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.7175 - accuracy: 0.7879 - val_loss: 2.0045 - val_accuracy: 0.5377\n",
            "Epoch 24/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.6741 - accuracy: 0.7979 - val_loss: 1.9344 - val_accuracy: 0.5424\n",
            "Epoch 25/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.6229 - accuracy: 0.8094 - val_loss: 1.9673 - val_accuracy: 0.5422\n",
            "Epoch 26/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.5688 - accuracy: 0.8285 - val_loss: 2.1362 - val_accuracy: 0.5420\n",
            "Epoch 27/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.5227 - accuracy: 0.8404 - val_loss: 2.1273 - val_accuracy: 0.5536\n",
            "Epoch 28/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.5092 - accuracy: 0.8457 - val_loss: 2.1447 - val_accuracy: 0.5458\n",
            "Epoch 29/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.4499 - accuracy: 0.8625 - val_loss: 2.1163 - val_accuracy: 0.5420\n",
            "Epoch 30/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.4170 - accuracy: 0.8711 - val_loss: 2.1376 - val_accuracy: 0.5432\n",
            "Epoch 31/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.4057 - accuracy: 0.8730 - val_loss: 2.1048 - val_accuracy: 0.5431\n",
            "Epoch 32/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.3767 - accuracy: 0.8827 - val_loss: 2.1389 - val_accuracy: 0.5443\n",
            "Epoch 33/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.3478 - accuracy: 0.8933 - val_loss: 2.3251 - val_accuracy: 0.5495\n",
            "Epoch 34/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.3379 - accuracy: 0.8945 - val_loss: 2.1360 - val_accuracy: 0.5459\n",
            "Epoch 35/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.3087 - accuracy: 0.9049 - val_loss: 2.3469 - val_accuracy: 0.5519\n",
            "Epoch 36/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.2972 - accuracy: 0.9072 - val_loss: 2.2494 - val_accuracy: 0.5442\n",
            "Epoch 37/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.2884 - accuracy: 0.9103 - val_loss: 2.3137 - val_accuracy: 0.5501\n",
            "Epoch 38/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.2739 - accuracy: 0.9117 - val_loss: 2.3481 - val_accuracy: 0.5503\n",
            "Epoch 39/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.2568 - accuracy: 0.9198 - val_loss: 2.3481 - val_accuracy: 0.5545\n",
            "Epoch 40/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.2447 - accuracy: 0.9219 - val_loss: 2.1493 - val_accuracy: 0.5453\n",
            "Epoch 41/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.2408 - accuracy: 0.9249 - val_loss: 2.2314 - val_accuracy: 0.5501\n",
            "Epoch 42/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.2306 - accuracy: 0.9286 - val_loss: 2.2911 - val_accuracy: 0.5433\n",
            "Epoch 43/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.2247 - accuracy: 0.9311 - val_loss: 2.5133 - val_accuracy: 0.5507\n",
            "Epoch 44/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.2243 - accuracy: 0.9304 - val_loss: 2.5775 - val_accuracy: 0.5560\n",
            "Epoch 45/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.2082 - accuracy: 0.9353 - val_loss: 2.3612 - val_accuracy: 0.5471\n",
            "Epoch 46/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1981 - accuracy: 0.9384 - val_loss: 2.3799 - val_accuracy: 0.5540\n",
            "Epoch 47/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1967 - accuracy: 0.9380 - val_loss: 2.5698 - val_accuracy: 0.5559\n",
            "Epoch 48/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1956 - accuracy: 0.9391 - val_loss: 2.4109 - val_accuracy: 0.5525\n",
            "Epoch 49/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1882 - accuracy: 0.9401 - val_loss: 2.6252 - val_accuracy: 0.5574\n",
            "Epoch 50/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1851 - accuracy: 0.9430 - val_loss: 2.5733 - val_accuracy: 0.5505\n",
            "Epoch 51/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1829 - accuracy: 0.9441 - val_loss: 2.4920 - val_accuracy: 0.5526\n",
            "Epoch 52/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1798 - accuracy: 0.9458 - val_loss: 2.4257 - val_accuracy: 0.5499\n",
            "Epoch 53/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1739 - accuracy: 0.9463 - val_loss: 2.5434 - val_accuracy: 0.5464\n",
            "Epoch 54/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1766 - accuracy: 0.9467 - val_loss: 2.6752 - val_accuracy: 0.5532\n",
            "Epoch 55/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1674 - accuracy: 0.9482 - val_loss: 2.4828 - val_accuracy: 0.5491\n",
            "Epoch 56/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1643 - accuracy: 0.9489 - val_loss: 2.6541 - val_accuracy: 0.5540\n",
            "Epoch 57/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1652 - accuracy: 0.9480 - val_loss: 2.7773 - val_accuracy: 0.5590\n",
            "Epoch 58/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1565 - accuracy: 0.9533 - val_loss: 2.7750 - val_accuracy: 0.5617\n",
            "Epoch 59/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1564 - accuracy: 0.9512 - val_loss: 2.4746 - val_accuracy: 0.5542\n",
            "Epoch 60/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1537 - accuracy: 0.9540 - val_loss: 2.7297 - val_accuracy: 0.5543\n",
            "Epoch 61/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1558 - accuracy: 0.9518 - val_loss: 2.4501 - val_accuracy: 0.5563\n",
            "Epoch 62/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1488 - accuracy: 0.9558 - val_loss: 2.5625 - val_accuracy: 0.5488\n",
            "Epoch 63/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1524 - accuracy: 0.9550 - val_loss: 2.4965 - val_accuracy: 0.5480\n",
            "Epoch 64/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1499 - accuracy: 0.9540 - val_loss: 2.2400 - val_accuracy: 0.5438\n",
            "Epoch 65/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.1491 - accuracy: 0.9556 - val_loss: 2.5940 - val_accuracy: 0.5565\n",
            "Epoch 66/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1446 - accuracy: 0.9555 - val_loss: 2.6835 - val_accuracy: 0.5537\n",
            "Epoch 67/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1475 - accuracy: 0.9552 - val_loss: 2.2401 - val_accuracy: 0.5317\n",
            "Epoch 68/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1441 - accuracy: 0.9585 - val_loss: 2.5692 - val_accuracy: 0.5472\n",
            "Epoch 69/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1440 - accuracy: 0.9582 - val_loss: 2.6119 - val_accuracy: 0.5513\n",
            "Epoch 70/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1479 - accuracy: 0.9548 - val_loss: 2.4011 - val_accuracy: 0.5502\n",
            "Epoch 71/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.1361 - accuracy: 0.9592 - val_loss: 2.5490 - val_accuracy: 0.5506\n",
            "Epoch 72/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.1378 - accuracy: 0.9577 - val_loss: 2.2859 - val_accuracy: 0.5478\n",
            "Epoch 73/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.1405 - accuracy: 0.9573 - val_loss: 2.6027 - val_accuracy: 0.5528\n",
            "Epoch 74/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1400 - accuracy: 0.9578 - val_loss: 2.6069 - val_accuracy: 0.5538\n",
            "Epoch 75/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1423 - accuracy: 0.9584 - val_loss: 2.3552 - val_accuracy: 0.5490\n",
            "Epoch 76/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1340 - accuracy: 0.9603 - val_loss: 2.7690 - val_accuracy: 0.5597\n",
            "Epoch 77/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.1338 - accuracy: 0.9603 - val_loss: 2.5254 - val_accuracy: 0.5538\n",
            "Epoch 78/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1384 - accuracy: 0.9604 - val_loss: 2.6589 - val_accuracy: 0.5562\n",
            "Epoch 79/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1372 - accuracy: 0.9590 - val_loss: 2.6696 - val_accuracy: 0.5434\n",
            "Epoch 80/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1374 - accuracy: 0.9588 - val_loss: 2.6113 - val_accuracy: 0.5529\n",
            "Epoch 81/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1364 - accuracy: 0.9598 - val_loss: 2.3239 - val_accuracy: 0.5511\n",
            "Epoch 82/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1291 - accuracy: 0.9627 - val_loss: 2.4441 - val_accuracy: 0.5545\n",
            "Epoch 83/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1322 - accuracy: 0.9614 - val_loss: 2.8300 - val_accuracy: 0.5565\n",
            "Epoch 84/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1391 - accuracy: 0.9604 - val_loss: 2.5633 - val_accuracy: 0.5524\n",
            "Epoch 85/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1324 - accuracy: 0.9609 - val_loss: 2.8279 - val_accuracy: 0.5550\n",
            "Epoch 86/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1353 - accuracy: 0.9602 - val_loss: 2.7358 - val_accuracy: 0.5545\n",
            "Epoch 87/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1394 - accuracy: 0.9601 - val_loss: 2.7214 - val_accuracy: 0.5506\n",
            "Epoch 88/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1285 - accuracy: 0.9629 - val_loss: 2.6077 - val_accuracy: 0.5503\n",
            "Epoch 89/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1259 - accuracy: 0.9633 - val_loss: 2.3016 - val_accuracy: 0.5415\n",
            "Epoch 90/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1261 - accuracy: 0.9638 - val_loss: 2.5382 - val_accuracy: 0.5537\n",
            "Epoch 91/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1303 - accuracy: 0.9627 - val_loss: 2.5910 - val_accuracy: 0.5496\n",
            "Epoch 92/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1262 - accuracy: 0.9638 - val_loss: 2.5437 - val_accuracy: 0.5496\n",
            "Epoch 93/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1211 - accuracy: 0.9646 - val_loss: 2.3789 - val_accuracy: 0.5488\n",
            "Epoch 94/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1311 - accuracy: 0.9633 - val_loss: 2.1285 - val_accuracy: 0.5044\n",
            "Epoch 95/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1316 - accuracy: 0.9624 - val_loss: 2.2485 - val_accuracy: 0.5455\n",
            "Epoch 96/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1239 - accuracy: 0.9640 - val_loss: 2.6209 - val_accuracy: 0.5547\n",
            "Epoch 97/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1248 - accuracy: 0.9647 - val_loss: 2.7554 - val_accuracy: 0.5501\n",
            "Epoch 98/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1287 - accuracy: 0.9636 - val_loss: 2.3178 - val_accuracy: 0.5410\n",
            "Epoch 99/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.1293 - accuracy: 0.9632 - val_loss: 2.9115 - val_accuracy: 0.5597\n",
            "Epoch 100/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1245 - accuracy: 0.9645 - val_loss: 2.4424 - val_accuracy: 0.5492\n",
            "Epoch 101/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1289 - accuracy: 0.9648 - val_loss: 2.1146 - val_accuracy: 0.5284\n",
            "Epoch 102/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1181 - accuracy: 0.9661 - val_loss: 2.5136 - val_accuracy: 0.5419\n",
            "Epoch 103/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1164 - accuracy: 0.9667 - val_loss: 2.6330 - val_accuracy: 0.5535\n",
            "Epoch 104/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1205 - accuracy: 0.9661 - val_loss: 2.6727 - val_accuracy: 0.5515\n",
            "Epoch 105/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.1224 - accuracy: 0.9640 - val_loss: 2.6184 - val_accuracy: 0.5497\n",
            "Epoch 106/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.1252 - accuracy: 0.9642 - val_loss: 2.2389 - val_accuracy: 0.5387\n",
            "Epoch 107/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.1234 - accuracy: 0.9648 - val_loss: 2.6886 - val_accuracy: 0.5543\n",
            "Epoch 108/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1150 - accuracy: 0.9669 - val_loss: 2.6314 - val_accuracy: 0.5480\n",
            "Epoch 109/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.1169 - accuracy: 0.9670 - val_loss: 2.7427 - val_accuracy: 0.5532\n",
            "Epoch 110/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1150 - accuracy: 0.9668 - val_loss: 2.2700 - val_accuracy: 0.5405\n",
            "Epoch 111/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.1164 - accuracy: 0.9668 - val_loss: 2.4500 - val_accuracy: 0.5506\n",
            "Epoch 112/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.1091 - accuracy: 0.9681 - val_loss: 2.8491 - val_accuracy: 0.5494\n",
            "Epoch 113/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.1169 - accuracy: 0.9653 - val_loss: 2.7970 - val_accuracy: 0.5473\n",
            "Epoch 114/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.1168 - accuracy: 0.9672 - val_loss: 2.2121 - val_accuracy: 0.5421\n",
            "Epoch 115/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.1207 - accuracy: 0.9669 - val_loss: 2.6195 - val_accuracy: 0.5539\n",
            "Epoch 116/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.1139 - accuracy: 0.9681 - val_loss: 2.5038 - val_accuracy: 0.5536\n",
            "Epoch 117/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.1071 - accuracy: 0.9696 - val_loss: 2.3201 - val_accuracy: 0.5492\n",
            "Epoch 118/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1070 - accuracy: 0.9689 - val_loss: 2.6048 - val_accuracy: 0.5506\n",
            "Epoch 119/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.1203 - accuracy: 0.9673 - val_loss: 3.2019 - val_accuracy: 0.5540\n",
            "Epoch 120/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.1102 - accuracy: 0.9682 - val_loss: 2.8549 - val_accuracy: 0.5555\n",
            "Epoch 121/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1093 - accuracy: 0.9692 - val_loss: 2.4333 - val_accuracy: 0.5494\n",
            "Epoch 122/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1079 - accuracy: 0.9705 - val_loss: 2.7118 - val_accuracy: 0.5561\n",
            "Epoch 123/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1062 - accuracy: 0.9701 - val_loss: 2.9318 - val_accuracy: 0.5542\n",
            "Epoch 124/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1093 - accuracy: 0.9701 - val_loss: 2.6574 - val_accuracy: 0.5531\n",
            "Epoch 125/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.1044 - accuracy: 0.9694 - val_loss: 2.5093 - val_accuracy: 0.5469\n",
            "Epoch 126/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1076 - accuracy: 0.9694 - val_loss: 2.6166 - val_accuracy: 0.5518\n",
            "Epoch 127/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1012 - accuracy: 0.9703 - val_loss: 2.4175 - val_accuracy: 0.5500\n",
            "Epoch 128/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1049 - accuracy: 0.9702 - val_loss: 2.3868 - val_accuracy: 0.5417\n",
            "Epoch 129/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.1009 - accuracy: 0.9713 - val_loss: 2.7284 - val_accuracy: 0.5484\n",
            "Epoch 130/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1026 - accuracy: 0.9708 - val_loss: 2.3308 - val_accuracy: 0.5432\n",
            "Epoch 131/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1016 - accuracy: 0.9700 - val_loss: 2.5456 - val_accuracy: 0.5476\n",
            "Epoch 132/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.0994 - accuracy: 0.9722 - val_loss: 2.4436 - val_accuracy: 0.5567\n",
            "Epoch 133/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1018 - accuracy: 0.9720 - val_loss: 2.5540 - val_accuracy: 0.5538\n",
            "Epoch 134/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.1050 - accuracy: 0.9697 - val_loss: 2.9910 - val_accuracy: 0.5546\n",
            "Epoch 135/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.0945 - accuracy: 0.9725 - val_loss: 2.7231 - val_accuracy: 0.5531\n",
            "Epoch 136/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.1002 - accuracy: 0.9716 - val_loss: 2.5861 - val_accuracy: 0.5533\n",
            "Epoch 137/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.1023 - accuracy: 0.9715 - val_loss: 2.2404 - val_accuracy: 0.5419\n",
            "Epoch 138/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.0994 - accuracy: 0.9708 - val_loss: 2.7262 - val_accuracy: 0.5510\n",
            "Epoch 139/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.0943 - accuracy: 0.9732 - val_loss: 2.2816 - val_accuracy: 0.5420\n",
            "Epoch 140/200\n",
            "782/782 [==============================] - 31s 39ms/step - loss: 0.0933 - accuracy: 0.9726 - val_loss: 2.4702 - val_accuracy: 0.5497\n",
            "Epoch 141/200\n",
            "782/782 [==============================] - 31s 39ms/step - loss: 0.0963 - accuracy: 0.9725 - val_loss: 2.5128 - val_accuracy: 0.5547\n",
            "Epoch 142/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.0938 - accuracy: 0.9733 - val_loss: 2.6168 - val_accuracy: 0.5566\n",
            "Epoch 143/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.0966 - accuracy: 0.9737 - val_loss: 3.0904 - val_accuracy: 0.5628\n",
            "Epoch 144/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.0951 - accuracy: 0.9728 - val_loss: 2.5410 - val_accuracy: 0.5434\n",
            "Epoch 145/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.0983 - accuracy: 0.9723 - val_loss: 2.6861 - val_accuracy: 0.5535\n",
            "Epoch 146/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.0924 - accuracy: 0.9735 - val_loss: 2.8414 - val_accuracy: 0.5602\n",
            "Epoch 147/200\n",
            "782/782 [==============================] - 31s 39ms/step - loss: 0.0983 - accuracy: 0.9727 - val_loss: 2.9805 - val_accuracy: 0.5563\n",
            "Epoch 148/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.0939 - accuracy: 0.9739 - val_loss: 2.6182 - val_accuracy: 0.5582\n",
            "Epoch 149/200\n",
            "782/782 [==============================] - 31s 39ms/step - loss: 0.0893 - accuracy: 0.9740 - val_loss: 2.2573 - val_accuracy: 0.5447\n",
            "Epoch 150/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.0904 - accuracy: 0.9746 - val_loss: 3.1500 - val_accuracy: 0.5558\n",
            "Epoch 151/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.0902 - accuracy: 0.9741 - val_loss: 2.4140 - val_accuracy: 0.5465\n",
            "Epoch 152/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.0888 - accuracy: 0.9745 - val_loss: 3.0719 - val_accuracy: 0.5559\n",
            "Epoch 153/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.0896 - accuracy: 0.9752 - val_loss: 2.6436 - val_accuracy: 0.5502\n",
            "Epoch 154/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.0927 - accuracy: 0.9740 - val_loss: 2.9455 - val_accuracy: 0.5485\n",
            "Epoch 155/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.0876 - accuracy: 0.9751 - val_loss: 2.4696 - val_accuracy: 0.5474\n",
            "Epoch 156/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.0825 - accuracy: 0.9756 - val_loss: 2.8807 - val_accuracy: 0.5577\n",
            "Epoch 157/200\n",
            "782/782 [==============================] - 31s 39ms/step - loss: 0.0850 - accuracy: 0.9749 - val_loss: 2.6116 - val_accuracy: 0.5546\n",
            "Epoch 158/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.0874 - accuracy: 0.9760 - val_loss: 2.4422 - val_accuracy: 0.5535\n",
            "Epoch 159/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.0872 - accuracy: 0.9753 - val_loss: 2.5034 - val_accuracy: 0.5474\n",
            "Epoch 160/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.0882 - accuracy: 0.9750 - val_loss: 2.9267 - val_accuracy: 0.5522\n",
            "Epoch 161/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.0848 - accuracy: 0.9757 - val_loss: 3.1220 - val_accuracy: 0.5540\n",
            "Epoch 162/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.0901 - accuracy: 0.9748 - val_loss: 2.5478 - val_accuracy: 0.5521\n",
            "Epoch 163/200\n",
            "782/782 [==============================] - 31s 39ms/step - loss: 0.0864 - accuracy: 0.9758 - val_loss: 2.8438 - val_accuracy: 0.5561\n",
            "Epoch 164/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.0774 - accuracy: 0.9783 - val_loss: 2.1060 - val_accuracy: 0.5278\n",
            "Epoch 165/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.0772 - accuracy: 0.9780 - val_loss: 2.4206 - val_accuracy: 0.5369\n",
            "Epoch 166/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.0817 - accuracy: 0.9768 - val_loss: 2.4771 - val_accuracy: 0.5483\n",
            "Epoch 167/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.0848 - accuracy: 0.9753 - val_loss: 3.0574 - val_accuracy: 0.5541\n",
            "Epoch 168/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.0847 - accuracy: 0.9767 - val_loss: 2.6300 - val_accuracy: 0.5523\n",
            "Epoch 169/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.0810 - accuracy: 0.9759 - val_loss: 2.5582 - val_accuracy: 0.5492\n",
            "Epoch 170/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.0772 - accuracy: 0.9778 - val_loss: 2.9361 - val_accuracy: 0.5595\n",
            "Epoch 171/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.0820 - accuracy: 0.9771 - val_loss: 3.2308 - val_accuracy: 0.5564\n",
            "Epoch 172/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.0890 - accuracy: 0.9752 - val_loss: 3.1287 - val_accuracy: 0.5547\n",
            "Epoch 173/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.0831 - accuracy: 0.9758 - val_loss: 2.6122 - val_accuracy: 0.5513\n",
            "Epoch 174/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.0778 - accuracy: 0.9772 - val_loss: 2.6815 - val_accuracy: 0.5562\n",
            "Epoch 175/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.0758 - accuracy: 0.9782 - val_loss: 2.9474 - val_accuracy: 0.5573\n",
            "Epoch 176/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.0764 - accuracy: 0.9786 - val_loss: 2.5438 - val_accuracy: 0.5545\n",
            "Epoch 177/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.0857 - accuracy: 0.9763 - val_loss: 2.9936 - val_accuracy: 0.5566\n",
            "Epoch 178/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.0745 - accuracy: 0.9782 - val_loss: 2.7860 - val_accuracy: 0.5562\n",
            "Epoch 179/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.0802 - accuracy: 0.9776 - val_loss: 2.9197 - val_accuracy: 0.5529\n",
            "Epoch 180/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.0800 - accuracy: 0.9781 - val_loss: 2.7794 - val_accuracy: 0.5517\n",
            "Epoch 181/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.0792 - accuracy: 0.9775 - val_loss: 2.8591 - val_accuracy: 0.5555\n",
            "Epoch 182/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.0782 - accuracy: 0.9775 - val_loss: 2.5415 - val_accuracy: 0.5463\n",
            "Epoch 183/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.0787 - accuracy: 0.9779 - val_loss: 2.4176 - val_accuracy: 0.5425\n",
            "Epoch 184/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.0832 - accuracy: 0.9769 - val_loss: 2.7278 - val_accuracy: 0.5588\n",
            "Epoch 185/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.0763 - accuracy: 0.9776 - val_loss: 2.8975 - val_accuracy: 0.5572\n",
            "Epoch 186/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.0777 - accuracy: 0.9780 - val_loss: 2.5270 - val_accuracy: 0.5482\n",
            "Epoch 187/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.0728 - accuracy: 0.9787 - val_loss: 3.1925 - val_accuracy: 0.5522\n",
            "Epoch 188/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.0762 - accuracy: 0.9774 - val_loss: 2.8657 - val_accuracy: 0.5560\n",
            "Epoch 189/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.0704 - accuracy: 0.9797 - val_loss: 3.0020 - val_accuracy: 0.5475\n",
            "Epoch 190/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.0746 - accuracy: 0.9782 - val_loss: 3.2488 - val_accuracy: 0.5563\n",
            "Epoch 191/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.0721 - accuracy: 0.9788 - val_loss: 2.4493 - val_accuracy: 0.5465\n",
            "Epoch 192/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.0724 - accuracy: 0.9788 - val_loss: 2.8070 - val_accuracy: 0.5562\n",
            "Epoch 193/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.0715 - accuracy: 0.9793 - val_loss: 2.8094 - val_accuracy: 0.5559\n",
            "Epoch 194/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.0747 - accuracy: 0.9783 - val_loss: 2.4031 - val_accuracy: 0.5417\n",
            "Epoch 195/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.0763 - accuracy: 0.9785 - val_loss: 2.7608 - val_accuracy: 0.5532\n",
            "Epoch 196/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.0725 - accuracy: 0.9789 - val_loss: 2.6356 - val_accuracy: 0.5568\n",
            "Epoch 197/200\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.0726 - accuracy: 0.9787 - val_loss: 2.9129 - val_accuracy: 0.5557\n",
            "Epoch 198/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.0721 - accuracy: 0.9795 - val_loss: 2.7753 - val_accuracy: 0.5570\n",
            "Epoch 199/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.0761 - accuracy: 0.9793 - val_loss: 2.2940 - val_accuracy: 0.5415\n",
            "Epoch 200/200\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.0730 - accuracy: 0.9799 - val_loss: 2.5529 - val_accuracy: 0.5519\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDxJHbFpsEeZ"
      },
      "source": [
        "# **Model Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEcjpNHwrt7-",
        "outputId": "15cc2165-9307-4144-b374-9caa6b8ab065"
      },
      "source": [
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.models import load_model\n",
        "\n",
        "# load and prepare the image\n",
        "def load_image(filename):\n",
        "\t# load the image\n",
        "\timg = load_img(filename, target_size=(32, 32))\n",
        "\t# convert to array\n",
        "\timg = img_to_array(img)\n",
        "\t# reshape into a single sample with 3 channels\n",
        "\timg = img.reshape(1, 32, 32, 3)\n",
        "\t# prepare pixel data\n",
        "\timg = img.astype('float32')\n",
        "\timg = img / 255.0\n",
        "\treturn img\n",
        "\n",
        "# load an image and predict the class\n",
        "def run_example():\n",
        "\t# load the image\n",
        "\timg = load_image('/content/sample_image.jpeg')\n",
        "\t# load model\n",
        "\tmodel = load_model('final_model.h5')\n",
        "\t# predict the class\n",
        "\tresult = model.predict_classes(img)\n",
        "\tprint(\"The image is of \",result[0])\n",
        "\n",
        "# entry point, run the example\n",
        "run_example()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The image is of  42\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}
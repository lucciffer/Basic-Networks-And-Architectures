{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k42iEVaKPIgo",
    "outputId": "6072398f-09a3-4e74-cbee-36068d6b9480"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat May 29 10:52:16 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   39C    P8     7W /  75W |      0MiB /  7611MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iRRRjx3nPWZX",
    "outputId": "d8e3813b-7bbb-41a1-a2d6-d88aab6dc68b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.41.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2020.12.5)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": "OK"
      }
     }
    },
    "id": "USBV3gehPZuD",
    "outputId": "22d49504-d802-4492-eb82-ec24a5d3dda8"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "VUcspBd_PgEd"
   },
   "outputs": [],
   "source": [
    "!mkdir -p ~/.kaggle \n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lA1wRnwktQzZ",
    "outputId": "fc35f144-0bf7-4d94-b4de-0502b2c350f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading flowers-recognition.zip to /content\n",
      "100% 450M/450M [00:03<00:00, 157MB/s]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d alxmamaev/flowers-recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "3p-DEYB0tVDr"
   },
   "outputs": [],
   "source": [
    "!unzip -q flowers-recognition.zip -d /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "bMatom_8yDJn"
   },
   "outputs": [],
   "source": [
    "!rm -rf /content/flowers/flowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "EtxPLdVnP1dF"
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lUt-XGfWQFJf",
    "outputId": "4688c890-3df8-4e48-f2b9-bcb24182a020"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "4tm-oH2rbxLg"
   },
   "outputs": [],
   "source": [
    "INIT_LR = 1e-4\n",
    "EPOCHS = 20\n",
    "BS = 32\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-VQswrDLY-3g",
    "outputId": "a83b7e1d-7d31-4860-bed0-739897f4e062"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting split_folders\n",
      "  Downloading https://files.pythonhosted.org/packages/b8/5f/3c2b2f7ea5e047c8cdc3bb00ae582c5438fcdbbedcc23b3cc1c2c7aae642/split_folders-0.4.3-py3-none-any.whl\n",
      "Installing collected packages: split-folders\n",
      "Successfully installed split-folders-0.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip install split_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "qphulJh5ZCU0"
   },
   "outputs": [],
   "source": [
    "import splitfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b03VPQAkZGKK",
    "outputId": "a2e3b156-6370-49a4-f27b-9531ac6544d7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 4326 files [00:00, 4937.26 files/s]\n"
     ]
    }
   ],
   "source": [
    "input_folder = '/content/flowers'\n",
    "output_folder = '/content/processed_data'\n",
    "\n",
    "splitfolders.ratio(input_folder, output_folder, seed=42, ratio=(.8, .1, .1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "pj5JyauiZnvq"
   },
   "outputs": [],
   "source": [
    "img_H = 224\n",
    "img_W = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Rp9v1H5aYfhU"
   },
   "outputs": [],
   "source": [
    "# DATALOADER - 02\n",
    "train_dir = '/content/processed_data/train'\n",
    "test_dir = '/content/processed_data/test'\n",
    "val_dir = '/content/processed_data/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "1kWE5vXpZ0aB"
   },
   "outputs": [],
   "source": [
    "# data generators\n",
    "train_data_gen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                    rotation_range = 20,\n",
    "                                    shear_range=0.15,\n",
    "                                    zoom_range=0.15,\n",
    "                                    horizontal_flip=True,\n",
    "                                    fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TATpHgY_aBHi",
    "outputId": "fb10ae6d-bb21-4c42-ca54-79bacde198e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3457 images belonging to 5 classes.\n",
      "Found 0 images belonging to 5 classes.\n",
      "Found 0 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = train_data_gen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_H, img_W),\n",
    "    batch_size =batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training')\n",
    "\n",
    "valid_gen = train_data_gen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(img_H, img_H),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation')\n",
    "\n",
    "test_gen = train_data_gen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_H, img_W),\n",
    "    batch_size=1,\n",
    "    class_mode='categorical',\n",
    "    subset='validation')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KDSuIaFSQKy_",
    "outputId": "5cd331d9-92ff-4e7b-981d-e4f54c54124a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9412608/9406464 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# load the MobileNetV2 network, ensuring the head FC layer sets are\n",
    "# left off\n",
    "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\n",
    "\tinput_tensor=Input(shape=(224, 224, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "twiO0XHPQK4U"
   },
   "outputs": [],
   "source": [
    "# construct the head of the model that will be placed on top of the\n",
    "# the base model\n",
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(5, activation=\"softmax\")(headModel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "ghsfeS3RQK7T"
   },
   "outputs": [],
   "source": [
    "# place the head FC model on top of the base model (this will become\n",
    "# the actual model we will train)\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "jZcevrJNQK-y"
   },
   "outputs": [],
   "source": [
    "# loop over all layers in the base model and freeze them so they will\n",
    "# *not* be updated during the first training process\n",
    "for layer in baseModel.layers:\n",
    "\tlayer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X-U0xDizQLCt",
    "outputId": "57241175-ccce-419b-92c4-ab72c74f8cab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    }
   ],
   "source": [
    "# compile our model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = Adam(learning_rate=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7qkSu8eFbMHk",
    "outputId": "4ad6b366-c243-4a3b-ca43-7674caaa99ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "109/109 [==============================] - 70s 364ms/step - loss: 1.3471 - accuracy: 0.4608\n",
      "Epoch 2/50\n",
      "109/109 [==============================] - 40s 371ms/step - loss: 0.8640 - accuracy: 0.6876\n",
      "Epoch 3/50\n",
      "109/109 [==============================] - 41s 380ms/step - loss: 0.6910 - accuracy: 0.7512\n",
      "Epoch 4/50\n",
      "109/109 [==============================] - 40s 364ms/step - loss: 0.6097 - accuracy: 0.7778\n",
      "Epoch 5/50\n",
      "109/109 [==============================] - 39s 362ms/step - loss: 0.5566 - accuracy: 0.8021\n",
      "Epoch 6/50\n",
      "109/109 [==============================] - 39s 360ms/step - loss: 0.5186 - accuracy: 0.8183\n",
      "Epoch 7/50\n",
      "109/109 [==============================] - 39s 358ms/step - loss: 0.4675 - accuracy: 0.8360\n",
      "Epoch 8/50\n",
      "109/109 [==============================] - 39s 361ms/step - loss: 0.4446 - accuracy: 0.8444\n",
      "Epoch 9/50\n",
      "109/109 [==============================] - 39s 360ms/step - loss: 0.4446 - accuracy: 0.8415\n",
      "Epoch 10/50\n",
      "109/109 [==============================] - 39s 359ms/step - loss: 0.3963 - accuracy: 0.8557\n",
      "Epoch 11/50\n",
      "109/109 [==============================] - 39s 360ms/step - loss: 0.3981 - accuracy: 0.8597\n",
      "Epoch 12/50\n",
      "109/109 [==============================] - 39s 358ms/step - loss: 0.3680 - accuracy: 0.8753\n",
      "Epoch 13/50\n",
      "109/109 [==============================] - 39s 356ms/step - loss: 0.3560 - accuracy: 0.8785\n",
      "Epoch 14/50\n",
      "109/109 [==============================] - 39s 358ms/step - loss: 0.3492 - accuracy: 0.8774\n",
      "Epoch 15/50\n",
      "109/109 [==============================] - 39s 358ms/step - loss: 0.3439 - accuracy: 0.8765\n",
      "Epoch 16/50\n",
      "109/109 [==============================] - 39s 358ms/step - loss: 0.3304 - accuracy: 0.8878\n",
      "Epoch 17/50\n",
      "109/109 [==============================] - 39s 358ms/step - loss: 0.3330 - accuracy: 0.8863\n",
      "Epoch 18/50\n",
      "109/109 [==============================] - 39s 356ms/step - loss: 0.3184 - accuracy: 0.8898\n",
      "Epoch 19/50\n",
      "109/109 [==============================] - 39s 355ms/step - loss: 0.3101 - accuracy: 0.8973\n",
      "Epoch 20/50\n",
      "109/109 [==============================] - 39s 354ms/step - loss: 0.2961 - accuracy: 0.8985\n",
      "Epoch 21/50\n",
      "109/109 [==============================] - 39s 356ms/step - loss: 0.2753 - accuracy: 0.9011\n",
      "Epoch 22/50\n",
      "109/109 [==============================] - 39s 357ms/step - loss: 0.2832 - accuracy: 0.8982\n",
      "Epoch 23/50\n",
      "109/109 [==============================] - 41s 373ms/step - loss: 0.2629 - accuracy: 0.9097\n",
      "Epoch 24/50\n",
      "109/109 [==============================] - 39s 360ms/step - loss: 0.2677 - accuracy: 0.9080\n",
      "Epoch 25/50\n",
      "109/109 [==============================] - 39s 361ms/step - loss: 0.2656 - accuracy: 0.9066\n",
      "Epoch 26/50\n",
      "109/109 [==============================] - 40s 367ms/step - loss: 0.2490 - accuracy: 0.9147\n",
      "Epoch 27/50\n",
      "109/109 [==============================] - 40s 366ms/step - loss: 0.2421 - accuracy: 0.9135\n",
      "Epoch 28/50\n",
      "109/109 [==============================] - 39s 355ms/step - loss: 0.2548 - accuracy: 0.9089\n",
      "Epoch 29/50\n",
      "109/109 [==============================] - 39s 356ms/step - loss: 0.2475 - accuracy: 0.9155\n",
      "Epoch 30/50\n",
      "109/109 [==============================] - 39s 361ms/step - loss: 0.2360 - accuracy: 0.9228\n",
      "Epoch 31/50\n",
      "109/109 [==============================] - 39s 362ms/step - loss: 0.2321 - accuracy: 0.9207\n",
      "Epoch 32/50\n",
      "109/109 [==============================] - 39s 361ms/step - loss: 0.2313 - accuracy: 0.9170\n",
      "Epoch 33/50\n",
      "109/109 [==============================] - 39s 362ms/step - loss: 0.2133 - accuracy: 0.9274\n",
      "Epoch 34/50\n",
      "109/109 [==============================] - 40s 362ms/step - loss: 0.2161 - accuracy: 0.9314\n",
      "Epoch 35/50\n",
      "109/109 [==============================] - 40s 363ms/step - loss: 0.2052 - accuracy: 0.9317\n",
      "Epoch 36/50\n",
      "109/109 [==============================] - 40s 363ms/step - loss: 0.2098 - accuracy: 0.9297\n",
      "Epoch 37/50\n",
      "109/109 [==============================] - 39s 361ms/step - loss: 0.2056 - accuracy: 0.9288\n",
      "Epoch 38/50\n",
      "109/109 [==============================] - 39s 362ms/step - loss: 0.2083 - accuracy: 0.9257\n",
      "Epoch 39/50\n",
      "109/109 [==============================] - 40s 362ms/step - loss: 0.2022 - accuracy: 0.9314\n",
      "Epoch 40/50\n",
      "109/109 [==============================] - 40s 366ms/step - loss: 0.1988 - accuracy: 0.9338\n",
      "Epoch 41/50\n",
      "109/109 [==============================] - 40s 364ms/step - loss: 0.1881 - accuracy: 0.9338\n",
      "Epoch 42/50\n",
      "109/109 [==============================] - 40s 365ms/step - loss: 0.1925 - accuracy: 0.9349\n",
      "Epoch 43/50\n",
      "109/109 [==============================] - 40s 364ms/step - loss: 0.1796 - accuracy: 0.9384\n",
      "Epoch 44/50\n",
      "109/109 [==============================] - 40s 367ms/step - loss: 0.1792 - accuracy: 0.9393\n",
      "Epoch 45/50\n",
      "109/109 [==============================] - 40s 364ms/step - loss: 0.1783 - accuracy: 0.9390\n",
      "Epoch 46/50\n",
      "109/109 [==============================] - 40s 366ms/step - loss: 0.1797 - accuracy: 0.9375\n",
      "Epoch 47/50\n",
      "109/109 [==============================] - 40s 365ms/step - loss: 0.1670 - accuracy: 0.9439\n",
      "Epoch 48/50\n",
      "109/109 [==============================] - 40s 371ms/step - loss: 0.1710 - accuracy: 0.9404\n",
      "Epoch 49/50\n",
      "109/109 [==============================] - 40s 367ms/step - loss: 0.1653 - accuracy: 0.9398\n",
      "Epoch 50/50\n",
      "109/109 [==============================] - 40s 365ms/step - loss: 0.1643 - accuracy: 0.9456\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_gen, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oJxiG0TeQLIO",
    "outputId": "bdc80a1a-37e5-4ce4-9483-6f9c5d9cb4fb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    }
   ],
   "source": [
    "model.save('/content/mnv2_3c.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SlNqddbHQLJ8"
   },
   "outputs": [],
   "source": [
    "model.summary() #breifs the architecture/layers/network-info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wniYghT9fX3z"
   },
   "source": [
    "# Testing predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zfcuha3hQLOm",
    "outputId": "bed5ed31-98ae-4fb5-eff4-92a643464f8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image is of  2\n",
      "The image is of  3\n",
      "The image is of  4\n",
      "The image is of  1\n",
      "The image is of  0\n"
     ]
    }
   ],
   "source": [
    "# make a prediction for a new image.\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import load_model\n",
    "\n",
    "# load and prepare the image\n",
    "def load_image(filename):\n",
    "\t# load the image\n",
    "\timg = load_img(filename, target_size=(224, 224))\n",
    "\t# convert to array\n",
    "\timg = img_to_array(img)\n",
    "\t# reshape into a single sample with 3 channels\n",
    "\timg = img.reshape(1, 224, 224, 3)\n",
    "\t# prepare pixel data\n",
    "\timg = img.astype('float32')\n",
    "\timg = img / 255.0\n",
    "\treturn img\n",
    "\n",
    "# load an image and predict the class\n",
    "# load the image\n",
    "img = load_image('/content/rose.jpg')\n",
    "img2 = load_image('/content/sunf.jpg')\n",
    "img3 = load_image('/content/tulip.jpg')\n",
    "img4 = load_image('/content/dandelion.jpg')\n",
    "img5 = load_image('/content/daisy.jpg')\n",
    "# load model\n",
    "model = load_model('/content/mnv2_3c.h5')\n",
    "#result = model.predict(img)\n",
    "  # predict the class\n",
    "#result = model.predict_classes(img)\n",
    "result = np.argmax(model.predict(img), axis=-1)\n",
    "result2 = np.argmax(model.predict(img2), axis=-1)\n",
    "result3 = np.argmax(model.predict(img3), axis=-1)\n",
    "result4 = np.argmax(model.predict(img4), axis=-1)\n",
    "result5 = np.argmax(model.predict(img5), axis=-1)\n",
    "print(\"The image is of \",result[0])\n",
    "print(\"The image is of \",result2[0])\n",
    "print(\"The image is of \",result3[0])\t\n",
    "print(\"The image is of \",result4[0])\n",
    "print(\"The image is of \",result5[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zyuglp7_f8TT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "mobilenetv2_multiclass.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
